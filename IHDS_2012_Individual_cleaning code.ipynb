{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13687dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee8e619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\User\\Desktop\\University of Manchester\\MSc Data Science\\Semester 2\\Dissertation\\Dataset\\IHDS data\\IHDS_2012\\IHDS_2012 csv file'\n",
    "df = pd.read_csv(path + '/' + 'IHDS_2012_D0001_Individual_selected var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fc9e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'STATEID', 'DISTID', 'PSUID', 'HHID', 'HHSPLITID', 'PERSONID',\n",
       "       'IDPSU', 'IDHH', 'IDPERSON', 'WT', 'FWT', 'DIST01', 'DISTRICT', 'RO3',\n",
       "       'RO4', 'RO5', 'RO6', 'RO7', 'RO8', 'RO9', 'RO10', 'FM38', 'NF13',\n",
       "       'NF33', 'NF53', 'ID11', 'WS4', 'WS5', 'WS8', 'WKANY5', 'WKDAYS', 'NF1',\n",
       "       'NFBN21', 'NFBN41'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cb071",
   "metadata": {},
   "source": [
    "## Rename Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad074cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename age(RO5), sex(RO3), industry(WS5), occupation(WS4),work hr per day(WS8), father id(RO9), mother id(r10), relationship to head(RO4)\n",
    "df = df.rename(columns={'RO5': 'age','RO3': 'sex', 'WS5':'industry', 'WS4': 'occup', 'WS8': 'wkhr_perday', 'RO9':'father_id', 'RO10':'mother_id','ID11':'religion', 'RO4':'relation_to_head','RO6':'mar_status', 'RO7':'activity_status', 'RO8':'spouse_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e37d66f",
   "metadata": {},
   "source": [
    "## Drop and Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f8971c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SURVEY                   1\n",
       "STATEID                  0\n",
       "DISTID                   0\n",
       "PSUID                    0\n",
       "HHID                     0\n",
       "HHSPLITID                0\n",
       "PERSONID                 1\n",
       "IDPSU                    0\n",
       "IDHH                     0\n",
       "IDPERSON                 1\n",
       "WT                       1\n",
       "FWT                      1\n",
       "DIST01                 106\n",
       "DISTRICT               106\n",
       "sex                      1\n",
       "relation_to_head         1\n",
       "age                      4\n",
       "mar_status               4\n",
       "activity_status          4\n",
       "spouse_id            92522\n",
       "father_id            49598\n",
       "mother_id            50099\n",
       "FM38                158337\n",
       "NF13                192574\n",
       "NF33                203391\n",
       "NF53                204462\n",
       "religion                 2\n",
       "occup               151117\n",
       "industry            151269\n",
       "wkhr_perday         151160\n",
       "WKANY5                   1\n",
       "WKDAYS                   1\n",
       "NF1                      1\n",
       "NFBN21                   1\n",
       "NFBN41                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in differetnt columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60659988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204569 entries, 0 to 204568\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   SURVEY            204568 non-null  object \n",
      " 1   STATEID           204569 non-null  object \n",
      " 2   DISTID            204569 non-null  int64  \n",
      " 3   PSUID             204569 non-null  int64  \n",
      " 4   HHID              204569 non-null  int64  \n",
      " 5   HHSPLITID         204569 non-null  int64  \n",
      " 6   PERSONID          204568 non-null  float64\n",
      " 7   IDPSU             204569 non-null  int64  \n",
      " 8   IDHH              204569 non-null  int64  \n",
      " 9   IDPERSON          204568 non-null  float64\n",
      " 10  WT                204568 non-null  float64\n",
      " 11  FWT               204568 non-null  float64\n",
      " 12  DIST01            204463 non-null  float64\n",
      " 13  DISTRICT          204463 non-null  object \n",
      " 14  sex               204568 non-null  object \n",
      " 15  relation_to_head  204568 non-null  object \n",
      " 16  age               204565 non-null  float64\n",
      " 17  mar_status        204565 non-null  object \n",
      " 18  activity_status   204565 non-null  object \n",
      " 19  spouse_id         112047 non-null  object \n",
      " 20  father_id         154971 non-null  object \n",
      " 21  mother_id         154470 non-null  object \n",
      " 22  FM38              46232 non-null   float64\n",
      " 23  NF13              11995 non-null   float64\n",
      " 24  NF33              1178 non-null    float64\n",
      " 25  NF53              107 non-null     float64\n",
      " 26  religion          204567 non-null  object \n",
      " 27  occup             53452 non-null   object \n",
      " 28  industry          53300 non-null   object \n",
      " 29  wkhr_perday       53409 non-null   float64\n",
      " 30  WKANY5            204568 non-null  object \n",
      " 31  WKDAYS            204568 non-null  float64\n",
      " 32  NF1               204568 non-null  object \n",
      " 33  NFBN21            204568 non-null  object \n",
      " 34  NFBN41            204568 non-null  object \n",
      "dtypes: float64(12), int64(6), object(17)\n",
      "memory usage: 54.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# 204569 entires before dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ee5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows if they have NAs in PERSONID, IDPERSON, DIST01, DISTRICT, sex, relation_to_head, religion, age, mar_status, activity_status, religion, WKANY5, WKDAYS\n",
    "\n",
    "columns_with_na = ['PERSONID', 'IDPERSON',  'sex', 'relation_to_head', 'religion', 'age', 'mar_status', 'activity_status', 'religion', 'WKANY5', 'WKDAYS'\n",
    "]\n",
    "df = df.dropna(axis=0, subset=columns_with_na)\n",
    "# remove 'DIST01', 'DISTRICT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84722b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 204558 entries, 0 to 204568\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   SURVEY            204558 non-null  object \n",
      " 1   STATEID           204558 non-null  object \n",
      " 2   DISTID            204558 non-null  int64  \n",
      " 3   PSUID             204558 non-null  int64  \n",
      " 4   HHID              204558 non-null  int64  \n",
      " 5   HHSPLITID         204558 non-null  int64  \n",
      " 6   PERSONID          204558 non-null  float64\n",
      " 7   IDPSU             204558 non-null  int64  \n",
      " 8   IDHH              204558 non-null  int64  \n",
      " 9   IDPERSON          204558 non-null  float64\n",
      " 10  WT                204558 non-null  float64\n",
      " 11  FWT               204558 non-null  float64\n",
      " 12  DIST01            204453 non-null  float64\n",
      " 13  DISTRICT          204453 non-null  object \n",
      " 14  sex               204558 non-null  object \n",
      " 15  relation_to_head  204558 non-null  object \n",
      " 16  age               204558 non-null  float64\n",
      " 17  mar_status        204558 non-null  object \n",
      " 18  activity_status   204558 non-null  object \n",
      " 19  spouse_id         112044 non-null  object \n",
      " 20  father_id         154964 non-null  object \n",
      " 21  mother_id         154463 non-null  object \n",
      " 22  FM38              46231 non-null   float64\n",
      " 23  NF13              11994 non-null   float64\n",
      " 24  NF33              1178 non-null    float64\n",
      " 25  NF53              107 non-null     float64\n",
      " 26  religion          204558 non-null  object \n",
      " 27  occup             53451 non-null   object \n",
      " 28  industry          53299 non-null   object \n",
      " 29  wkhr_perday       53408 non-null   float64\n",
      " 30  WKANY5            204558 non-null  object \n",
      " 31  WKDAYS            204558 non-null  float64\n",
      " 32  NF1               204558 non-null  object \n",
      " 33  NFBN21            204558 non-null  object \n",
      " 34  NFBN41            204558 non-null  object \n",
      "dtypes: float64(12), int64(6), object(17)\n",
      "memory usage: 56.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#204453 entries left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8404ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SURVEY                   0\n",
       "STATEID                  0\n",
       "DISTID                   0\n",
       "PSUID                    0\n",
       "HHID                     0\n",
       "HHSPLITID                0\n",
       "PERSONID                 0\n",
       "IDPSU                    0\n",
       "IDHH                     0\n",
       "IDPERSON                 0\n",
       "WT                       0\n",
       "FWT                      0\n",
       "DIST01                   0\n",
       "DISTRICT                 0\n",
       "sex                      0\n",
       "relation_to_head         0\n",
       "age                      0\n",
       "mar_status               0\n",
       "activity_status          0\n",
       "spouse_id            92460\n",
       "father_id            49569\n",
       "mother_id            50070\n",
       "FM38                158246\n",
       "NF13                192459\n",
       "NF33                203275\n",
       "NF53                204346\n",
       "religion                 0\n",
       "occup               151036\n",
       "industry            151188\n",
       "wkhr_perday         151079\n",
       "WKANY5                   0\n",
       "WKDAYS                   0\n",
       "NF1                      0\n",
       "NFBN21                   0\n",
       "NFBN41                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values of different variables again\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a043d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occup'].fillna('999', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00302d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2281      Manuf agents 41\n",
       "3073      Manuf agents 41\n",
       "5024      Manuf agents 41\n",
       "5820      Manuf agents 41\n",
       "11429     Manuf agents 41\n",
       "               ...       \n",
       "197075    Manuf agents 41\n",
       "198566    Manuf agents 41\n",
       "199752    Manuf agents 41\n",
       "199921    Manuf agents 41\n",
       "202575    Manuf agents 41\n",
       "Name: occup, Length: 82, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['occup'].str.contains('41')]['occup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649d0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for wkhr_perday, FM38, NF13, NF33, NF53, occup, industry, father_id, mother_id\n",
    "df['wkhr_perday'].fillna(0, inplace=True)\n",
    "df['FM38'].fillna(0, inplace=True)\n",
    "df['NF13'].fillna(0, inplace=True)\n",
    "df['NF33'].fillna(0, inplace=True)\n",
    "df['NF53'].fillna(0, inplace=True)\n",
    "# assign 999 to impute missing values in occup, industry, father_id and mother_id to represent none \n",
    "df['occup'].fillna(999, inplace=True)\n",
    "df['industry'].fillna(999, inplace=True)\n",
    "df['father_id'].fillna(999, inplace=True)\n",
    "df['mother_id'].fillna(999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a17c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     204346\n",
       "8.0         20\n",
       "2.0         16\n",
       "6.0         15\n",
       "4.0         14\n",
       "3.0          8\n",
       "9.0          8\n",
       "10.0         7\n",
       "12.0         7\n",
       "5.0          5\n",
       "1.0          4\n",
       "7.0          3\n",
       "Name: NF53, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the range of wkhr_perday, FM38, NF13, NF33, NF53 (set the maximum as 16 hours per day)\n",
    "df['wkhr_perday'].value_counts()\n",
    "df['FM38'].value_counts()\n",
    "df['NF13'].value_counts()\n",
    "df['NF33'].value_counts()\n",
    "df['NF53'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2a026",
   "metadata": {},
   "source": [
    "## Encode existing variables using new matching of values and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e0608e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    102451\n",
       "0    102002\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sex\n",
    "df['sex'].value_counts()\n",
    "# Replace Female 2 with 1, Male 1 with 0\n",
    "df['sex'] = df['sex'].replace(['Female 2', 'Male 1'],[1, 0])\n",
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa757b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation\n",
    "df['occup'].value_counts()\n",
    "\n",
    "# remove all the space characters in occup\n",
    "df['occup'] = df['occup'].replace(' ','')\n",
    "\n",
    "# remove all the string characters in occup, leaving only the NOC code\n",
    "df['occup'] = df['occup'].str.replace('\\D','', regex = True)\n",
    "\n",
    "# impute NA with 999\n",
    "df['occup'].fillna(999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37edd481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999    151036\n",
       "63      15295\n",
       "95      13623\n",
       "98       2197\n",
       "15       2076\n",
       "        ...  \n",
       "5           7\n",
       "11          3\n",
       "67          3\n",
       "10          2\n",
       "6           1\n",
       "Name: occup, Length: 93, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e186650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation\n",
    "df['industry'].value_counts()\n",
    "\n",
    "# remove all the space characters in occup\n",
    "df['industry'] = df['industry'].replace(' ','')\n",
    "\n",
    "# remove all the string characters in occup, leaving only the NIC code\n",
    "df['industry'] = df['industry'].str.replace('\\D','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f45bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15496\n",
       "50    13127\n",
       "92     2753\n",
       "70     2559\n",
       "37     1800\n",
       "      ...  \n",
       "13       13\n",
       "98        9\n",
       "84        8\n",
       "4         5\n",
       "14        3\n",
       "Name: industry, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec0960",
   "metadata": {},
   "source": [
    "## Compute new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be01c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayhours?\n",
    "#dayhours =  FM38+ NF13 + NF33+ NF53+ wkhr_perday\n",
    "#df['dayhours'] = df['FM38'] + df['NF13'] + df['NF33'] + df['NF53'] + df['wkhr_perday']\n",
    "#df['dayhours'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18eec1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age groups\n",
    "# define age_group function\n",
    "def age_group(x):\n",
    "    if x <=4:\n",
    "        return 0\n",
    "    elif x>=5 and x <=11:\n",
    "        return 1\n",
    "    elif x>=12 and x <=14:\n",
    "        return 2\n",
    "    elif x>=15 and x <=17:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "# apply age_group function on df['age'] to create new column 'age_gp'\n",
    "df['age_gp'] = df['age'].apply(age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b542ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      151079\n",
       "56.0      37046\n",
       "42.0       3977\n",
       "70.0       2761\n",
       "49.0       2465\n",
       "63.0       2026\n",
       "84.0       1487\n",
       "35.0       1475\n",
       "28.0       1077\n",
       "21.0        336\n",
       "14.0        260\n",
       "77.0        158\n",
       "112.0       115\n",
       "7.0          80\n",
       "98.0         44\n",
       "105.0        38\n",
       "91.0         29\n",
       "Name: total_wk_hr, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_wk_hr\n",
    "# total_wk_hr = wkhr_perday * 7\n",
    "df['total_wk_hr'] = df['wkhr_perday']*7\n",
    "df['total_wk_hr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e206aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_father_id_from_son and unique_father_id_from_father\n",
    "df['father_id'].value_counts()\n",
    "\n",
    "# Assign 99 to replace the string values in father_id\n",
    "df['father_id'] = df['father_id'].replace(['Dead','IF Spouse/Parent outside for more than 6 months'],[99,99])\n",
    "\n",
    "# Convert the dtype of PERSONID\n",
    "df['PERSONID'] = df['PERSONID'].astype(int)\n",
    "\n",
    "# Compute unique_father_id_from_son\n",
    "# use np.int64 as dtype instead of int, otherwise there will be value error\n",
    "df['unique_father_id_from_spouse'] = df['IDHH'].apply(str) + df['father_id'].apply(str)\n",
    "df['unique_father_id_from_spouse'] = df['unique_father_id_from_spouse'].astype(np.int64)\n",
    "\n",
    "# Compute unique_father_id_from_father\n",
    "df['unique_father_id_from_father'] = df['IDHH'].apply(str) + df['PERSONID'].apply(str)\n",
    "df['unique_father_id_from_father'] = df['unique_father_id_from_father'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfe2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_mother_id_from_son and unique_mother_id_from_mother\n",
    "df['mother_id'].value_counts()\n",
    "\n",
    "# Assign 99 to replace the string values in mother_id\n",
    "df['mother_id'] = df['mother_id'].replace(['Dead','IF Spouse/Parent outside for more than 6 months'],[99,99])\n",
    "\n",
    "# Convert the dtype of PERSONID\n",
    "df['PERSONID'] = df['PERSONID'].astype(int)\n",
    "\n",
    "# Compute unique_mother_id_from_spouse\n",
    "# use np.int64 as dtype instead of int, otherwise there will be value error\n",
    "df['unique_mother_id_from_spouse'] = df['IDHH'].apply(str) + df['mother_id'].apply(str)\n",
    "df['unique_mother_id_from_spouse'] = df['unique_mother_id_from_spouse'].astype(np.int64)\n",
    "\n",
    "# Compute unique_mother_id_from_spouse\n",
    "#df['unique_father_id_from_father'] = int(str(df['IDHH'])+str(df['PERSONID']))\n",
    "df['unique_mother_id_from_mother'] = df['IDHH'].apply(str) + df['PERSONID'].apply(str)\n",
    "df['unique_mother_id_from_mother'] = df['unique_mother_id_from_mother'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b7c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hazardousness\n",
    "# has to categorise different occupations according to the hazardous work list first\n",
    "hazard_occ_list = [24,71,50,51,52,53,54,66,72,73,74,75,76,78,80,81,82,85,87,88,89,90,91,92]\n",
    "# Create a new column hazard to indicate the hazardousness of the occupation\n",
    "def hazard_occup(x):\n",
    "    hazard_occ_list = ['24','71','50','51','52','53','54','66','72','73','74','75','76','78','80','81','82','85','87','88','89','90','91','92']\n",
    "    if x != '':\n",
    "        if x in(hazard_occ_list):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "df['hazard'] = df['occup'].apply(hazard_occup) \n",
    "# Impute NA with 0\n",
    "df['hazard'].fillna(0, inplace=True)\n",
    "# Convert the dtype of df['hazard']\n",
    "df['hazard'] = df['hazard'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b59ecd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197647\n",
       "1      6806\n",
       "Name: hazard, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hazard'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ef18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(path + '/' +'IHDS_2012_cleaning data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28198fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent variable: Incidence of Child Labour (CL_incidence)\n",
    "# Use np.select to create new column representing incidence of child labour\n",
    "conditions = [\n",
    "    ((df['hazard'] == 1) & (df['age_gp'] >=1) & (df['age_gp'] <=3)),\n",
    "    ((df['age_gp'] == 1) & (df['total_wk_hr'] >=1)),\n",
    "    ((df['age_gp'] == 2) & (df['total_wk_hr'] >=14)),\n",
    "    ((df['age_gp'] == 3) & (df['total_wk_hr'] >=43))\n",
    "]\n",
    "choices = [1, 1, 1, 1]\n",
    "# create CL_incidence\n",
    "df['CL_incidence'] = np.select(conditions, choices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1768c634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 204453 entries, 0 to 204568\n",
      "Data columns (total 43 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   SURVEY                        204453 non-null  object \n",
      " 1   STATEID                       204453 non-null  object \n",
      " 2   DISTID                        204453 non-null  int64  \n",
      " 3   PSUID                         204453 non-null  int64  \n",
      " 4   HHID                          204453 non-null  int64  \n",
      " 5   HHSPLITID                     204453 non-null  int64  \n",
      " 6   PERSONID                      204453 non-null  int32  \n",
      " 7   IDPSU                         204453 non-null  int64  \n",
      " 8   IDHH                          204453 non-null  int64  \n",
      " 9   IDPERSON                      204453 non-null  float64\n",
      " 10  WT                            204453 non-null  float64\n",
      " 11  FWT                           204453 non-null  float64\n",
      " 12  DIST01                        204453 non-null  float64\n",
      " 13  DISTRICT                      204453 non-null  object \n",
      " 14  sex                           204453 non-null  int64  \n",
      " 15  relation_to_head              204453 non-null  object \n",
      " 16  age                           204453 non-null  float64\n",
      " 17  mar_status                    204453 non-null  object \n",
      " 18  activity_status               204453 non-null  object \n",
      " 19  spouse_id                     111993 non-null  object \n",
      " 20  father_id                     204453 non-null  object \n",
      " 21  mother_id                     204453 non-null  object \n",
      " 22  FM38                          204453 non-null  float64\n",
      " 23  NF13                          204453 non-null  float64\n",
      " 24  NF33                          204453 non-null  float64\n",
      " 25  NF53                          204453 non-null  float64\n",
      " 26  religion                      204453 non-null  object \n",
      " 27  occup                         204453 non-null  object \n",
      " 28  industry                      53265 non-null   object \n",
      " 29  wkhr_perday                   204453 non-null  float64\n",
      " 30  WKANY5                        204453 non-null  object \n",
      " 31  WKDAYS                        204453 non-null  float64\n",
      " 32  NF1                           204453 non-null  object \n",
      " 33  NFBN21                        204453 non-null  object \n",
      " 34  NFBN41                        204453 non-null  object \n",
      " 35  age_gp                        204453 non-null  int64  \n",
      " 36  total_wk_hr                   204453 non-null  float64\n",
      " 37  unique_father_id_from_spouse  204453 non-null  int64  \n",
      " 38  unique_father_id_from_father  204453 non-null  int64  \n",
      " 39  unique_mother_id_from_spouse  204453 non-null  int64  \n",
      " 40  unique_mother_id_from_mother  204453 non-null  int64  \n",
      " 41  hazard                        204453 non-null  int64  \n",
      " 42  CL_incidence                  204453 non-null  int32  \n",
      "dtypes: float64(12), int32(2), int64(13), object(16)\n",
      "memory usage: 67.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9cab941",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_child' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15080/2776979916.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_child\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CL_incidence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_child' is not defined"
     ]
    }
   ],
   "source": [
    "# df_child['CL_incidence'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72fa032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV score: 0.968 +/- 0.000\n",
      "The score on test data: 0.9662398137369034\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.110904\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           CL_incidence   No. Observations:                46379\n",
      "Model:                          Logit   Df Residuals:                    46368\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Mon, 03 Jul 2023   Pseudo R-squ.:                  0.2225\n",
      "Time:                        03:01:10   Log-Likelihood:                -5143.6\n",
      "converged:                      False   LL-Null:                       -6615.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "sex                     -0.6617      0.057    -11.563      0.000      -0.774      -0.550\n",
      "age                      0.5533      0.015     38.081      0.000       0.525       0.582\n",
      "religion_Buddhist 5    -10.4647      0.400    -26.193      0.000     -11.248      -9.682\n",
      "religion_Christian 3   -11.0967      0.311    -35.665      0.000     -11.707     -10.487\n",
      "religion_Hindu 1       -10.7565      0.225    -47.711      0.000     -11.198     -10.315\n",
      "religion_Jain 6        -26.2678   1445.597     -0.018      0.986   -2859.586    2807.050\n",
      "religion_Muslim 2      -10.4169      0.230    -45.269      0.000     -10.868      -9.966\n",
      "religion_None 9        -25.9474   3735.755     -0.007      0.994   -7347.892    7295.998\n",
      "religion_Others 8       -9.5193      0.689    -13.809      0.000     -10.870      -8.168\n",
      "religion_Sikh 4        -10.6595      0.281    -37.867      0.000     -11.211     -10.108\n",
      "religion_Tribal 7      -11.2188      0.567    -19.802      0.000     -12.329     -10.108\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# binomial multiple logistic regression\n",
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# create the training and testing data\n",
    "df_child = df[(df['age_gp'] >=1) & (df['age_gp'] <=3)]\n",
    "df_child = df_child[['sex','age', 'religion','CL_incidence','IDHH']]\n",
    "\n",
    "# create dummy variables for religion\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.OneHotEncoder(sparse = False)\n",
    "encoder.fit(df_child[['religion']])\n",
    "encoder.transform(df_child[['religion']])\n",
    "df_child[encoder.get_feature_names_out()] = encoder.transform(df_child[['religion']])\n",
    "df_child = df_child.drop(columns = 'religion')\n",
    "df_child\n",
    "\n",
    "# split the data for training and testing\n",
    "response = df_child['CL_incidence']\n",
    "feature = df_child.drop(columns=['CL_incidence','IDHH'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, response, test_size = 0.1)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv = 10)\n",
    "print(f'10-fold CV score: {scores.mean():.3f} +/- {scores.std():.3f}')\n",
    "print(f'The score on test data: {logreg.score(X_test, y_test)}')\n",
    "\n",
    "# Print the model result summary\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train, X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87a25713",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (64,167,168,169,170,171,182,183,195,226,420,447,514,616,622,635,642,644,694) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# merge with houshold dataset to get the household features\n",
    "# read the household dataset csv file\n",
    "df_hh = pd.read_csv(path + '/' + 'IHDS_2012_D0002_Household.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65a82df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'STATEID', 'DISTID', 'PSUID', 'HHID', 'HHSPLITID', 'IDPSU',\n",
       "       'IDHH', 'WT', 'INDWT',\n",
       "       ...\n",
       "       'NWKANY5', 'INCNONAG', 'INCAGLAB', 'INCSALARY', 'INCNREGA',\n",
       "       'INCNONNREGA', 'NNR', 'HHEDUC', 'HHEDUCM', 'HHEDUCF'],\n",
       "      dtype='object', length=758)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b1befd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = ['SURVEY', 'STATEID', 'DISTID', 'PSUID', 'HHID', 'HHSPLITID', \n",
    "       'IDPSU', 'IDHH', 'WT', 'FWT', 'DIST01', 'DISTRICT','NPERSONS','ID13',\n",
    "        'HHEDUC', 'POOR', 'COPC', 'SATOILET', 'WATER']\n",
    "df_hh = df_hh[selected_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c07e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hh.to_csv(path+'/'+ 'IHDS_2012_Household_selected_var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66aaf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42152 entries, 0 to 42151\n",
      "Data columns (total 19 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SURVEY     42152 non-null  object \n",
      " 1   STATEID    42152 non-null  object \n",
      " 2   DISTID     42152 non-null  int64  \n",
      " 3   PSUID      42152 non-null  int64  \n",
      " 4   HHID       42152 non-null  int64  \n",
      " 5   HHSPLITID  42152 non-null  int64  \n",
      " 6   IDPSU      42152 non-null  int64  \n",
      " 7   IDHH       42152 non-null  int64  \n",
      " 8   WT         42152 non-null  float64\n",
      " 9   FWT        42152 non-null  int64  \n",
      " 10  DIST01     42152 non-null  int64  \n",
      " 11  DISTRICT   42152 non-null  object \n",
      " 12  NPERSONS   42152 non-null  int64  \n",
      " 13  ID13       42066 non-null  object \n",
      " 14  HHEDUC     42141 non-null  object \n",
      " 15  POOR       42129 non-null  object \n",
      " 16  COPC       42129 non-null  float64\n",
      " 17  SATOILET   41978 non-null  object \n",
      " 18  WATER      41995 non-null  object \n",
      "dtypes: float64(2), int64(9), object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1b7b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge two datasets by using householdID\n",
    "df_merged = df_child.merge(df_hh, how='inner', on = 'IDHH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e0b767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(path+'/'+'IHDS_2012_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1355c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d658eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute and Encode variables\n",
    "# WATER\n",
    "\n",
    "# remove all the space characters in water\n",
    "df['WATER'] = df['WATER'].replace(' ','')\n",
    "\n",
    "# remove all the string characters in water\n",
    "df['WATER'] = df['WATER'].str.replace('\\D','', regex = True)\n",
    "\n",
    "# impute NA with 0\n",
    "df['WATER'].fillna(method = 'bfill', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a17c7205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WATER'] = df['WATER'].astype(np.int64)\n",
    "df['WATER'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc202388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5f677a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POOR\n",
    "\n",
    "# remove all the space characters in water\n",
    "df['POOR'] = df['POOR'].replace(' ','')\n",
    "\n",
    "# remove all the string characters in water\n",
    "df['POOR'] = df['POOR'].str.replace('\\D','', regex = True)\n",
    "\n",
    "# impute NA with backfill\n",
    "df['POOR'].fillna(method='bfill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6021a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POOR'] = df['POOR'].astype(np.int64)\n",
    "df['POOR'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53a6ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['COPC'].fillna(df['COPC'].mean(), inplace = True)\n",
    "df['COPC'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02166737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c220903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV score: 0.967 +/- 0.000\n",
      "The score on test data: 0.9691501746216531\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.105411\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           CL_incidence   No. Observations:                46379\n",
      "Model:                          Logit   Df Residuals:                    46365\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Jul 2023   Pseudo R-squ.:                  0.2667\n",
      "Time:                        03:02:30   Log-Likelihood:                -4888.9\n",
      "converged:                      False   LL-Null:                       -6666.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "sex                     -0.7306      0.058    -12.584      0.000      -0.844      -0.617\n",
      "age                      0.6017      0.015     39.581      0.000       0.572       0.632\n",
      "religion_Hindu 1       -10.6862      0.244    -43.824      0.000     -11.164     -10.208\n",
      "religion_Muslim 2      -10.4315      0.249    -41.975      0.000     -10.919      -9.944\n",
      "religion_Christian 3   -10.8540      0.331    -32.813      0.000     -11.502     -10.206\n",
      "religion_Sikh 4        -10.2226      0.302    -33.889      0.000     -10.814      -9.631\n",
      "religion_Buddhist 5    -10.3033      0.399    -25.846      0.000     -11.085      -9.522\n",
      "religion_Jain 6        -27.6343   3775.511     -0.007      0.994   -7427.500    7372.232\n",
      "religion_Tribal 7      -11.5096      0.580    -19.834      0.000     -12.647     -10.372\n",
      "religion_Others 8       -9.3923      0.731    -12.845      0.000     -10.825      -7.959\n",
      "religion_None 9        -26.3734   4534.007     -0.006      0.995   -8912.863    8860.116\n",
      "POOR                     0.3789      0.072      5.261      0.000       0.238       0.520\n",
      "WATER                   -0.5262      0.075     -7.020      0.000      -0.673      -0.379\n",
      "COPC                 -3.963e-05   3.61e-06    -10.990      0.000   -4.67e-05   -3.26e-05\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Binomial multiple logistic regression 2\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# split the data for training and testing\n",
    "response = df['CL_incidence']\n",
    "feature = df[['sex', 'age', 'religion_Hindu 1', 'religion_Muslim 2', 'religion_Christian 3', 'religion_Sikh 4', 'religion_Buddhist 5','religion_Jain 6', 'religion_Tribal 7', 'religion_Others 8', 'religion_None 9', 'POOR', 'WATER', 'COPC']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, response, test_size = 0.1)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv = 10)\n",
    "print(f'10-fold CV score: {scores.mean():.3f} +/- {scores.std():.3f}')\n",
    "print(f'The score on test data: {logreg.score(X_test, y_test)}')\n",
    "\n",
    "# Print the model result summary\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train, X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dc365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
